{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m[DEBUG]\tDETECTING BLOCKS...\u001b[0m\n",
      "\u001b[1m\u001b[34m[DEBUG]\tUsing YOLOv8: /home/toto/ros_ws/src/UR5LegoVision/vision/yolov8-training/weights/8l-594.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "/home/toto/ros_ws/src/UR5LegoVision/lego_builder/output/output.png does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/toto/ros_ws/src/UR5LegoVision/vision/scripts/localization/detect_img.ipynb Cell 1\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/toto/ros_ws/src/UR5LegoVision/vision/scripts/localization/detect_img.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Imgage path\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/toto/ros_ws/src/UR5LegoVision/vision/scripts/localization/detect_img.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m IMG_PATH \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/home/toto/ros_ws/src/UR5LegoVision/lego_builder/output/output.png\u001b[39m\u001b[39m'\u001b[39m \n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/toto/ros_ws/src/UR5LegoVision/vision/scripts/localization/detect_img.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m legoDetect \u001b[39m=\u001b[39m BlockDetect(IMG_PATH)\n",
      "File \u001b[0;32m~/ros_ws/src/UR5LegoVision/vision/scripts/localization/BlockDetect.py:68\u001b[0m, in \u001b[0;36mBlockDetect.__init__\u001b[0;34m(self, img_path, save_result, open_result)\u001b[0m\n\u001b[1;32m     65\u001b[0m log\u001b[39m.\u001b[39mdebug_highlight(\u001b[39m'\u001b[39m\u001b[39mDETECTING BLOCKS...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblock_list \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 68\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdetect(img_path, open_result)\n\u001b[1;32m     70\u001b[0m \u001b[39mif\u001b[39;00m save_result:\n\u001b[1;32m     71\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmove_detect_result_to(LOG_FOLDER)\n",
      "File \u001b[0;32m~/ros_ws/src/UR5LegoVision/vision/scripts/localization/BlockDetect.py:86\u001b[0m, in \u001b[0;36mBlockDetect.detect\u001b[0;34m(self, img_path, open_result)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39m# Detection model\u001b[39;00m\n\u001b[1;32m     85\u001b[0m log\u001b[39m.\u001b[39mdebug_highlight(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUsing YOLOv8: \u001b[39m\u001b[39m{\u001b[39;00mWEIGHTS_PATH\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 86\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(source\u001b[39m=\u001b[39;49mimg_path, conf\u001b[39m=\u001b[39;49mCONFIDENCE, save\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, line_width\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m     87\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults[\u001b[39m0\u001b[39m]\n\u001b[1;32m     89\u001b[0m \u001b[39m# Bounding boxes\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/ultralytics/engine/model.py:246\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor, \u001b[39m'\u001b[39m\u001b[39mset_prompts\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    245\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor\u001b[39m.\u001b[39mset_prompts(prompts)\n\u001b[0;32m--> 246\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor\u001b[39m.\u001b[39mpredict_cli(source\u001b[39m=\u001b[39msource) \u001b[39mif\u001b[39;00m is_cli \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredictor(source\u001b[39m=\u001b[39;49msource, stream\u001b[39m=\u001b[39;49mstream)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/ultralytics/engine/predictor.py:197\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream_inference(source, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    196\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream_inference(source, model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py:43\u001b[0m, in \u001b[0;36m_DecoratorContextManager._wrap_generator.<locals>.generator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     \u001b[39m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 43\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     45\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m             \u001b[39m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/ultralytics/engine/predictor.py:229\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msetup_model(model)\n\u001b[1;32m    228\u001b[0m \u001b[39m# Setup source every time predict is called\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msetup_source(source \u001b[39mif\u001b[39;49;00m source \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49msource)\n\u001b[1;32m    231\u001b[0m \u001b[39m# Check if save_dir/ label file exists\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39msave \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39msave_txt:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/ultralytics/engine/predictor.py:210\u001b[0m, in \u001b[0;36mBasePredictor.setup_source\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimgsz \u001b[39m=\u001b[39m check_imgsz(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mimgsz, stride\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mstride, min_dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)  \u001b[39m# check image size\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mmodel, \u001b[39m'\u001b[39m\u001b[39mtransforms\u001b[39m\u001b[39m'\u001b[39m, classify_transforms(\n\u001b[1;32m    209\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimgsz[\u001b[39m0\u001b[39m])) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mtask \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mclassify\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset \u001b[39m=\u001b[39m load_inference_source(source\u001b[39m=\u001b[39;49msource, imgsz\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimgsz, vid_stride\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mvid_stride)\n\u001b[1;32m    211\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_type \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39msource_type\n\u001b[1;32m    212\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mTrue\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m  \u001b[39m# streams\u001b[39;00m\n\u001b[1;32m    213\u001b[0m                                           \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset) \u001b[39m>\u001b[39m \u001b[39m1000\u001b[39m \u001b[39mor\u001b[39;00m  \u001b[39m# images\u001b[39;00m\n\u001b[1;32m    214\u001b[0m                                           \u001b[39many\u001b[39m(\u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset, \u001b[39m'\u001b[39m\u001b[39mvideo_flag\u001b[39m\u001b[39m'\u001b[39m, [\u001b[39mFalse\u001b[39;00m]))):  \u001b[39m# videos\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/ultralytics/data/build.py:165\u001b[0m, in \u001b[0;36mload_inference_source\u001b[0;34m(source, imgsz, vid_stride)\u001b[0m\n\u001b[1;32m    163\u001b[0m     dataset \u001b[39m=\u001b[39m LoadPilAndNumpy(source, imgsz\u001b[39m=\u001b[39mimgsz)\n\u001b[1;32m    164\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     dataset \u001b[39m=\u001b[39m LoadImages(source, imgsz\u001b[39m=\u001b[39;49mimgsz, vid_stride\u001b[39m=\u001b[39;49mvid_stride)\n\u001b[1;32m    167\u001b[0m \u001b[39m# Attach source types to the dataset\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[39msetattr\u001b[39m(dataset, \u001b[39m'\u001b[39m\u001b[39msource_type\u001b[39m\u001b[39m'\u001b[39m, source_type)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/ultralytics/data/loaders.py:183\u001b[0m, in \u001b[0;36mLoadImages.__init__\u001b[0;34m(self, path, imgsz, vid_stride)\u001b[0m\n\u001b[1;32m    181\u001b[0m         files\u001b[39m.\u001b[39mappend(\u001b[39mstr\u001b[39m((parent \u001b[39m/\u001b[39m p)\u001b[39m.\u001b[39mabsolute()))  \u001b[39m# files (relative to *.txt file parent)\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 183\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mp\u001b[39m}\u001b[39;00m\u001b[39m does not exist\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    185\u001b[0m images \u001b[39m=\u001b[39m [x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m files \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mlower() \u001b[39min\u001b[39;00m IMG_FORMATS]\n\u001b[1;32m    186\u001b[0m videos \u001b[39m=\u001b[39m [x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m files \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mlower() \u001b[39min\u001b[39;00m VID_FORMATS]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: /home/toto/ros_ws/src/UR5LegoVision/lego_builder/output/output.png does not exist"
     ]
    }
   ],
   "source": [
    "from BlockDetect import BlockDetect\n",
    "\n",
    "# Imgage path\n",
    "IMG_PATH = '/home/toto/ros_ws/src/UR5LegoVision/lego_builder/output/output.png' \n",
    "\n",
    "legoDetect = BlockDetect(IMG_PATH)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
